{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32d1d976-7036-48be-a57d-3876fa4b261d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install uv --quiet\n",
    "!uv sync --active --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a2cfbd3-d144-49e2-ab23-792cc453c888",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../tools/report_finder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e879e6-5c00-43dc-957e-b07d17274ee2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../tools/metric_calculator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ed66058-f310-4dfe-a35f-72143f77eb4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../tools/visual_generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afd7c4dd-6a41-4d0c-8cdf-58b43d488882",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../tools/database_searcher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83ef553e-8a1d-495c-86e3-3025779a2023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../tools/web_news_searcher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "933efd96-e515-4a96-9b35-775cca8ad3dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../tools/report_assembler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc626e66-1835-4f32-b4d9-f1cb82d80433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../agent_config/callback_handler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed671952-dc9f-48cd-ab7b-9634eaeb1c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import toml\n",
    "import pyspark.sql.functions as F\n",
    "from databricks_langchain import ChatDatabricks\n",
    "import datetime\n",
    "from typing import Any, Generator, Optional, Sequence, Union\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import ChatAgentMessage, ChatAgentResponse, ChatAgentChunk, ChatContext\n",
    "from mlflow.types.llm import ChatCompletionResponse, ChatChoice, ChatMessage, ChatCompletionChunk, ChatChunkChoice, ChatChoiceDelta\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AIMessageChunk,\n",
    "    BaseMessage,\n",
    "    convert_to_openai_messages,\n",
    ")\n",
    "from pydantic import BaseModel, create_model\n",
    "from typing import Annotated, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "854711c1-0315-43ce-a7c3-862d2f54419f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "env_vars = toml.load(\"../../conf/env_vars.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b776b91-f774-4371-bfa3-271bb5ea30d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [LoggingHandler()]\n",
    "\n",
    "LLM_ENDPOINT_NAME = env_vars[\"LLM_ENDPOINT_NAME\"]\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "619101e3-9535-4785-b076-cdf495a1b713",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "\"Você é um analista de dados em saúde que consulta dados do SUS (Sistema Único de Saúde do Brasil) sobre síndrome respiratória grave e retorna um relatório diário sobre a situação da doença trazendo métricas relevantes e as respectivas explicações que ajudem a explicar o cenário atual. Você utiliza vocabulário técnico em suas respostas e relatórios gerados\"\n",
    "\n",
    "Passo 1: Utilize a ferramenta srag_report_finder_tool para encontrar o relatório diário mais atualizado sobre a situação da doença e carregar as informações contidas nele.\n",
    "\n",
    "Caso você não encontre um relatório do dia, utiliza o passo 2 para gerar um novo relatório. Se voê encontrou o relatório da data atual, siga para o passo 3.\n",
    "Passo 2:\n",
    "- Utiliza a ferramenta srag_metric_calculator_tool para conehcer todas as métricas epidemiológicas que são incluídas no relatório.\n",
    "- Utilize a ferramenta srag_plot_generator_tool para obter informações sobre os gráficos relevantes para o relatório.\n",
    "- Utilize a ferramenta web_searcher_tool para efetuar uma busca informações na internet sobre o cenário atual da Sindrome Respiratória Aguda Grave a fim de contextualizar o resultado das métricas e visualizações encontradas.\n",
    "- Em seguida sumarize os resultados encontrados sobre a doença SRAG e forneça a resposta final da análise efetuada em um dict que será usado como input da ferramenta report_assembler_tool.\n",
    "O dict deve conter os seguintes campos:\n",
    "    - srag_description: Breve descrição de SRAG, em até 150 palavras, u.\n",
    "    - comment_cases_evolution_count: Um comentário de até 150 palavras sobre a evolução do número de casos mês atual, nos ultimos meses,  de forma geral e nos diferentes estados.\n",
    "    - conclusions_disease_evolution_icu_occupation: Uma conclusão de até 300 palavras sobre a evolução do número de casos, taxa de pacientes vacinados e taxa de ocupação da UTI nos últimos meses, contextualizando com notícias atuais.\n",
    "- Chame a ferramenta report_assembler_tool e passe como argumento o dict com os 3 itens acima.\n",
    "\n",
    "Passo 3:\n",
    "Agora que você possui um relatório padrão de SRAG e suas informações, você pode responder perguntas do usuário sobre SRAG/doenças respiratórias.\n",
    "Caso o usuário perguntar alguma métrica não incluída no relatório, use a ferramenta database_searcher_tool para buscar informações no banco de dados de SRAG (tabela srag_features). Você acessar a tabela srag_features_dictionary para obter uma descrição de cada coluna existente na tabela srag_features. Você deve preferir fazer perguntas diretas ao agente database_searcher_tool, ao invés queries de READ em SQL.\n",
    "Voc6e também pode usar a ferramenta web_searcher_tool para efetuar uma nova busca informações na internet sobre o cenário atual da Sindrome Respiratória Aguda Grave. Não utilize essa ferrament mais de 2 vezes.\n",
    "\n",
    "Mesmo que o usuário não pergunte sobre o relatório, ao final da respsota sempre chame a ferramenta report_assembler_tool para gerar/exibir o relatório final junto com a resposta solicitada. Você não deve chamar a ferramenta report_assembler_tool mais de uma vez.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0039f1f9-105e-4a1b-aea0-7b55228c0e9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "srag_report_finder_tool = FindTodaySRAGReportTool()\n",
    "database_searcher_tool = SparkSQLQueryTool()\n",
    "web_searcher_tool = TavilyTool()\n",
    "report_assembler_tool = GenerateSRAGReportTool()\n",
    "\n",
    "# Create the metric calculator StructuredTool\n",
    "srag_metric_calculator_tool = StructuredTool.from_function(\n",
    "    func=SRAGMetrics().generate_report_metrics,\n",
    "    name=\"generate_srag_report_metrics\",\n",
    "    description=(\n",
    "        \"Generates SRAG epidemiological metrics (counts, variation, ICU admission, \"\n",
    "        \"HTML ICU tables) for report generation.\"\n",
    "    ),\n",
    "    structured_output_schema=SRAGMetricsOutput,\n",
    "    return_direct=True\n",
    ")\n",
    "\n",
    "# Create the plot generator StructuredTool\n",
    "srag_plot_generator_tool = StructuredTool.from_function(\n",
    "    func=SRAGVisualization().generate_plot_data,\n",
    "    name=\"generate_srag_report_plots\",\n",
    "    description=(\n",
    "        \"Compute SRAG statistic data used for report visualization, including time series, \"\n",
    "        \"UF choropleth, and vaccination rate charts.\"\n",
    "    ),\n",
    "    structured_output_schema=SRAGPlotsOutput,\n",
    "    return_direct=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b42a657-2409-4c05-87cf-c279d0286dda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tools = []\n",
    "tools.append(srag_report_finder_tool)\n",
    "tools.append(srag_metric_calculator_tool)\n",
    "tools.append(srag_plot_generator_tool)\n",
    "tools.append(database_searcher_tool)\n",
    "tools.append(web_searcher_tool)\n",
    "tools.append(report_assembler_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ce23d78-f37a-4e85-9f56-3c3ee33de4a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Define the agent logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ead9b119-140f-4c4a-a448-8ba1fe930c89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  The state for the agent workflow, including the conversation and any custom data\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    custom_inputs: Optional[dict[str, Any]]\n",
    "    custom_outputs: Optional[dict[str, Any]]\n",
    "\n",
    "# Define the LangGraph agent that can call tools\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "    system_prompt: Optional[str] = None,\n",
    ") -> CompiledStateGraph:\n",
    "    # Bind tools to the model\n",
    "    model = model.bind_tools(tools)  \n",
    "\n",
    "    # Function to check if agent should continue or finish based on last message\n",
    "    def routing_logic(state: ChatAgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If function (tool) calls are present, continue; otherwise, end\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    # Preprocess: optionally prepend a system prompt to the conversation history\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "\n",
    "    model_runnable = preprocessor | model  # Chain the preprocessor and the model\n",
    "\n",
    "    # The function to invoke the model within the workflow\n",
    "    def call_model(\n",
    "        state: ChatAgentState,\n",
    "        config: RunnableConfig,\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    workflow = StateGraph(ChatAgentState)  # Create the agent\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))  # Agent node (LLM)\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))            # Tools node\n",
    "\n",
    "    workflow.set_entry_point(\"agent\")  # Start at agent node\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        routing_logic,\n",
    "        {\n",
    "            \"continue\": \"tools\",  # If the model requests a tool call, move to tools node\n",
    "            \"end\": END,           # Otherwise, end the workflow\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")  # After tools are called, return to agent node\n",
    "\n",
    "    # Compile and return the tool-calling agent workflow\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59ca5c61-e2cb-4084-996b-b2adc1b76e53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class LangGraphAgent(ChatAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: Sequence[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        messages = []\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "\n",
    "                )\n",
    "        return ChatAgentResponse(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10619521-fddf-4c58-9440-01fc84e7b786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mlflow.langchain.autolog()\n",
    "# Create the agent graph with an LLM, tool set, and system prompt (if given)\n",
    "agent = create_tool_calling_agent(llm, tools, system_prompt)\n",
    "AGENT = LangGraphAgent(agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35f91de3-f669-4374-9ac2-9c548f53a986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "717878be-13c2-408a-82b3-e6b2f0a3a5dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"O que é SRAG?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49e66adc-e7f7-4a97-bb0c-27eca676b885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"Qual a taxa de mortalidade por SRAG esse mês no Brazil?\"}]})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "agent.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
