{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32d1d976-7036-48be-a57d-3876fa4b261d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install uv --quiet\n",
    "!uv sync --active --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e879e6-5c00-43dc-957e-b07d17274ee2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %run ../tools/metric_calculator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afd7c4dd-6a41-4d0c-8cdf-58b43d488882",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../tools/database_searcher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83ef553e-8a1d-495c-86e3-3025779a2023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../tools/web_news_searcher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc626e66-1835-4f32-b4d9-f1cb82d80433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../agent_config/callback_handler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed671952-dc9f-48cd-ab7b-9634eaeb1c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import toml\n",
    "import pyspark.sql.functions as F\n",
    "from databricks_langchain import ChatDatabricks\n",
    "import datetime\n",
    "from typing import Any, Generator, Optional, Sequence, Union\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import ChatAgentMessage, ChatAgentResponse, ChatAgentChunk, ChatContext\n",
    "from mlflow.types.llm import ChatCompletionResponse, ChatChoice, ChatMessage, ChatCompletionChunk, ChatChunkChoice, ChatChoiceDelta\n",
    "from langchain_core.tools import StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "854711c1-0315-43ce-a7c3-862d2f54419f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "env_vars = toml.load(\"../../conf/env_vars.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b776b91-f774-4371-bfa3-271bb5ea30d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [LoggingHandler()]\n",
    "\n",
    "LLM_ENDPOINT_NAME = env_vars[\"LLM_ENDPOINT_NAME\"]\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, callbacks=callbacks)\n",
    "\n",
    "# system_prompt = \"Você é um analista de dados em saúde que consulta dados do SUS (Sistema Único de Saúde do Brasil) sobre síndrome respiratória grave e retorna um relatório diário sobre a situação da doença trazendo métricas relevantes e as respectivas explicações que ajudem a explicar o cenário atual.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "619101e3-9535-4785-b076-cdf495a1b713",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "\"Você é um analista de dados em saúde que consulta dados do SUS (Sistema Único de Saúde do Brasil) sobre síndrome respiratória grave e retorna um relatório diário sobre a situação da doença trazendo métricas relevantes e as respectivas explicações que ajudem a explicar o cenário atual.\"\n",
    "\n",
    "Para resolver a tarefa você tem acesso às ferramentas:\n",
    "Você pode calcular algumas das métricas através das tools:\n",
    "get_month_mortality_rate()\n",
    "\n",
    "Caso não houver uma ferramenta específica para calcular uma métrica, você usar a ferramenta database_searcher para buscar informações no banco de dados de SRAG. Você pode fazer a pergunta diretamente ao agente database_searcher, conferir as suas repostas e logs, e se necessário fazer queries de READ em SQL na tabela srag_features.\n",
    "\n",
    "Utilize a tool search_query para fazer uma busca na internet sobre o cenário atual da Sindrome Respiratória Aguda Grave a fim de contextualizar o resultado das métricas encontradas (se houverem).\n",
    "\n",
    "Em seguida sumarize os resultados e forneça a resposta final da análise efetuada.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51517385-8f0e-4521-991f-6b898f3ceb35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# metric_calculator = SRAGMetrics()\n",
    "# metric_calculator_tool = StructuredTool.from_function(func=metric_calculator.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb3c8d4a-86f0-4a26-bbba-2c8dafaa5915",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# @tool\n",
    "# def get_month_mortality_rate(month: Optional[str | int] = None, year: Optional[str | int] = None) -> str:\n",
    "#     \"\"\"\n",
    "#     Call to returns the mortality rate(%) for the given month of a year or for the current month.\n",
    "#     \"\"\"\n",
    "#     today = datetime.date.today()\n",
    "#     if month is None:\n",
    "#         month = today.month\n",
    "#     if year is None:\n",
    "#         year = today.year\n",
    "#     else:\n",
    "#         month = int(month)\n",
    "#         year = int(year)\n",
    "#     feature_store_table_name = f'{env_vars[\"CATALOG\"]}.{env_vars[\"SCHEMA\"]}.srag_features'\n",
    "#     feature_store_table = spark.read.table(feature_store_table_name)\n",
    "#     mortality_rate_percent = feature_store_table.filter(\n",
    "#         (F.year(F.col(\"DT_EVOLUCA\")).cast(\"int\") == year) &\n",
    "#         (F.month(F.col(\"DT_EVOLUCA\")).cast(\"int\") == month)\n",
    "#         ).select(\n",
    "#         F.last(\"mortalidade_mensal_perc\")\n",
    "#     ).collect()[0][0]\n",
    "#     return f\"The mortality rate (%) for {month} of {year} is {mortality_rate_percent}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0039f1f9-105e-4a1b-aea0-7b55228c0e9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain_core.tools import BaseTool, tool\n",
    "# from langchain_tavily import TavilySearch\n",
    "# from tavily import TavilyClient\n",
    "\n",
    "# @tool\n",
    "# def search_news(search_query:str):\n",
    "#     \"\"\"Use this tool to search for news articles related to the current topic. The input to this tool should be a search query and the output will be a list of news articles.\"\"\"\n",
    "#     load_dotenv()\n",
    "#     tavily_api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "#     tavily_client = TavilyClient(api_key=tavily_api_key)\n",
    "    \n",
    "#     resp = tavily_client.search(\n",
    "#         query=search_query,\n",
    "#         max_results=3,\n",
    "#         search_depth=\"basic\",\n",
    "#         time_range=\"month\",\n",
    "#         country=\"brazil\",\n",
    "#         )\n",
    "#     context = []\n",
    "#     context.append({\n",
    "#         \"news\": [\n",
    "#             { \"title\": result[\"title\"], \"title\": result[\"content\"], \"url\": result[\"url\"]} for result in resp[\"results\"]\n",
    "#         ]\n",
    "#     })\n",
    "#     return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "839242a9-71b4-4480-aa00-d90427558a18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "database_searcher = SparkSQLQueryTool()\n",
    "web_search_query = TavilyTool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b42a657-2409-4c05-87cf-c279d0286dda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tools = []\n",
    "# tools.append(metric_calculator_tool)\n",
    "tools.append(database_searcher)\n",
    "tools.append(web_search_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ce23d78-f37a-4e85-9f56-3c3ee33de4a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Define the agent logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b01b7f-1785-4751-8169-3d9b31e37e68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AIMessageChunk,\n",
    "    BaseMessage,\n",
    "    convert_to_openai_messages,\n",
    ")\n",
    "from pydantic import BaseModel, create_model\n",
    "from typing import Annotated, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ead9b119-140f-4c4a-a448-8ba1fe930c89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  The state for the agent workflow, including the conversation and any custom data\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    custom_inputs: Optional[dict[str, Any]]\n",
    "    custom_outputs: Optional[dict[str, Any]]\n",
    "\n",
    "# Define the LangGraph agent that can call tools\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "    system_prompt: Optional[str] = None,\n",
    ") -> CompiledStateGraph:\n",
    "    # Bind tools to the model\n",
    "    model = model.bind_tools(tools)  \n",
    "\n",
    "    # Function to check if agent should continue or finish based on last message\n",
    "    def routing_logic(state: ChatAgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If function (tool) calls are present, continue; otherwise, end\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    # Preprocess: optionally prepend a system prompt to the conversation history\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "\n",
    "    model_runnable = preprocessor | model  # Chain the preprocessor and the model\n",
    "\n",
    "    # The function to invoke the model within the workflow\n",
    "    def call_model(\n",
    "        state: ChatAgentState,\n",
    "        config: RunnableConfig,\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    workflow = StateGraph(ChatAgentState)  # Create the agent\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))  # Agent node (LLM)\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))            # Tools node\n",
    "\n",
    "    workflow.set_entry_point(\"agent\")  # Start at agent node\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        routing_logic,\n",
    "        {\n",
    "            \"continue\": \"tools\",  # If the model requests a tool call, move to tools node\n",
    "            \"end\": END,           # Otherwise, end the workflow\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")  # After tools are called, return to agent node\n",
    "\n",
    "    # Compile and return the tool-calling agent workflow\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59ca5c61-e2cb-4084-996b-b2adc1b76e53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class LangGraphAgent(ChatAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: Sequence[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "        messages = []\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "\n",
    "                )\n",
    "        return ChatAgentResponse(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10619521-fddf-4c58-9440-01fc84e7b786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mlflow.langchain.autolog()\n",
    "# Create the agent graph with an LLM, tool set, and system prompt (if given)\n",
    "agent = create_tool_calling_agent(llm, tools, system_prompt)\n",
    "AGENT = LangGraphAgent(agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35f91de3-f669-4374-9ac2-9c548f53a986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49e66adc-e7f7-4a97-bb0c-27eca676b885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"Qual a taxa de mortalidade por SRAG esse mês no Brazil?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "717878be-13c2-408a-82b3-e6b2f0a3a5dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"O que é SRAG?\"}]})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "orquestrator_agent.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
