# AcuteResp-AgentTracker: Agente Analista de S√≠ndrome Respirat√≥ria Aguda Grave (DataSUS)

Este projeto implementa uma **solu√ß√£o de IA generativa com agentes** para ingest√£o, transforma√ß√£o e an√°lise de dados de **SRAG (S√≠ndrome Respirat√≥ria Aguda Grave)** disponibilizados pelo **DataSUS**.
O agente gera automaticamente o relat√≥rio di√°rio de SRAG e tamb√©m pode ser usado pelo usu√°rio para obter informa√ß√µes sobre a doen√ßa ou os dados existentes. Para interagir com o agente utilize o notebook chat_ai.

A solu√ß√£o gera **relat√≥rios HTML automatizados**, contendo:
- Principais **m√©tricas epidemiol√≥gicas** sobre a doen√ßa
- **Visualiza√ß√µes interativas** (gr√°ficos e tabelas)
- **Explica√ß√µes em linguagem natural**, contextualizando os indicadores calculados com base em **not√≠cias di√°rias da web**, permitindo uma leitura anal√≠tica e atualizada do cen√°rio epidemiol√≥gico

O projeto foi desenvolvido para rodar no **Databricks Free Edition**, utilizando **Databricks Asset Bundles (DAB)** para padronizar o deploy e a execu√ß√£o.

O fluxo principal √© composto por um **agente de IA generativa** que executa as seguintes etapas:

1. **Ingest√£o de dados**  
   - Download e leitura dos dados p√∫blicos de SRAG do DataSUS

2. **Transforma√ß√£o**  
   - Limpeza e padroniza√ß√£o dos dados
   - Cria√ß√£o de m√©tricas epidemiol√≥gicas (casos, √≥bitos, taxas, evolu√ß√£o temporal, etc.)

3. **Gera√ß√£o de visualiza√ß√µes**  
   - Gr√°ficos temporais, distribui√ß√µes geogr√°ficas e indicadores-chave

4. **Contextualiza√ß√£o com IA generativa**  
   - Coleta de not√≠cias recentes da web
   - Gera√ß√£o de explica√ß√µes textuais que relacionam os dados com o contexto atual

5. **Gera√ß√£o de relat√≥rios HTML**  
   - Relat√≥rios prontos para compartilhamento

## üìÅ Estrutura do Reposit√≥rio

```
.   
‚îú‚îÄ‚îÄ conf/                               # Arquivos de configura√ß√£o.   
‚îú‚îÄ‚îÄ reports/                            # Relat√≥rios di√°rios de SRAG.   
‚îÇ   ‚îî‚îÄ‚îÄ report.html                     # Relat√≥rio final em HTML gerado para o dia.  
‚îú‚îÄ‚îÄ scratch/                            # Notebooks de explora√ß√£o.   
‚îú‚îÄ‚îÄ resources/                          # Notebooks para explora√ß√£o.   
‚îú‚îÄ‚îÄ src/                                # C√≥digo-fonte principal da aplica√ß√£o.   
‚îÇ   ‚îú‚îÄ‚îÄ agents/                         # Agentes respons√°veis pela execu√ß√£o do relat√≥rio.
‚îÇ       ‚îî‚îÄ‚îÄ agent.py                    # C√≥digo de estrutura√ß√£o do agente.  
‚îÇ       ‚îî‚îÄ‚îÄ agent_environment.py        # C√≥digo para cria√ß√£o do serving endpoint.   
‚îÇ       ‚îî‚îÄ‚îÄ deploy_agent.py             # C√≥digo para execu√ß√£o do deploy do agente.   
‚îÇ       ‚îî‚îÄ‚îÄ daily_report_generator.py   # Notebook que executa o modelo para gerar o relat√≥rio di√°rio de SRAG
‚îÇ       ‚îî‚îÄ‚îÄ chat_ai.py                  # Notebook que carrega o modelo e permite o envio de perguntas personalizadas aoa gente. 
‚îÇ   ‚îú‚îÄ‚îÄ agent_config/                   # Arquivos de configura√ß√£o do agente.   
‚îÇ       ‚îî‚îÄ‚îÄ callback_handler.py         # C√≥digo para captura de logs de eventos nas chamadas do agente.   
‚îÇ       ‚îî‚îÄ‚îÄ prompt.py                   # System prompt.   
‚îÇ   ‚îú‚îÄ‚îÄ elt/                            # Extract, load and transform data.   
‚îÇ       ‚îî‚îÄ‚îÄ extract_static_data.py      # Extra√ß√£o de dados antigos/est√°ticos.   
‚îÇ       ‚îî‚îÄ‚îÄ extract_refreshing_data.py  # Extra√ß√£o de dados que s√£o atualidos com frequ√™ncia.   
‚îÇ       ‚îî‚îÄ‚îÄ feature_engineering.py      # Tranforma√ß√£o de dados para  engenharia de features.   
‚îÇ   ‚îú‚îÄ‚îÄ tools/                          # Ferramentas (tools) executadas pelos agentes.   
‚îÇ       ‚îî‚îÄ‚îÄ metric_calculator.py        # Ferramenta que calcula as m√©tricas de SRAG.   
‚îÇ       ‚îî‚îÄ‚îÄ visual_generator.py         # Ferramenta que plota as visualiza√ß√µes do relat√≥rio.   
‚îÇ       ‚îî‚îÄ‚îÄ web_news_searcher.py        # Ferramenta que recebe uma query do agente e faz uma busca de not√≠cias na web.   
‚îÇ       ‚îî‚îÄ‚îÄ database_searcher.py        # Agente/Ferramenta que faz spark queries nas tabelas para responder perguntas 
‚îÇ                                         do usu√°rio sobre os dados.   
‚îÇ       ‚îî‚îÄ‚îÄ report_finder.py            # Ferramenta que busca se existe um relat√≥rio j√° gerado no dia atual.
‚îÇ       ‚îî‚îÄ‚îÄ report_assembler.py         # Ferramenta que recebe dicion√°rios contendo not√≠cias, m√©tricas e visualiza√ß√µes e 
‚îÇ                                         compila o relat√≥rio.   
‚îÇ   ‚îú‚îÄ‚îÄ utils/                          # Arquivos utilit√°rios.   
‚îÇ       ‚îî‚îÄ‚îÄ srag_report_template.html   # Template do relat√≥rio.   
‚îÇ       ‚îî‚îÄ‚îÄ general_helpers.py          # Fun√ß√µes utilit√°rias.  
‚îú‚îÄ‚îÄ .env.example                        # Arquivo de exemplo para vari√°veis de ambiente.   
‚îú‚îÄ‚îÄ pyproject.toml                      # Arquivo de configura√ß√£o de depend√™ncias Python.   
‚îî‚îÄ‚îÄ README.md                           # Documenta√ß√£o do projeto.   
```


## Pr√©-requisitos

- Conta **Databricks Free Edition**
- Conta no **GitHub**
- OpenAI API chave paga  GPT-5 (https://openai.com/index/openai-api/)
- Free API key Tavily search (https://www.tavily.com/)
- Git instalado localmente (opcional, mas recomendado quando usado localmente)
- Databricks CLI (uso local)


## Como criar uma conta no Databricks Free Edition

1. Acesse: https://www.databricks.com/try-databricks
2. Selecione **Free Edition**
3. Crie sua conta utilizando e-mail ou login do GitHub
4. Ap√≥s a cria√ß√£o, voc√™ ser√° redirecionado para o **Databricks Workspace**

A Free Edition √© suficiente para executar este projeto e testar agentes de IA.


## Como configurar a conex√£o do GitHub com o Databricks

1. No Databricks Workspace, clique no seu avatar (canto superior direito)
2. V√° em **Settings ‚Üí Linked accounts**
3. Em **Git Integration**, selecione **GitHub**
4. Autorize o acesso do Databricks √† sua conta GitHub

Alternativamente, voc√™ pode usar um **GitHub Personal Access Token (PAT)**:
- Crie o token no GitHub
- Cole o token na configura√ß√£o de Git Integration do Databricks


## Como clonar o reposit√≥rio no Databricks


### Op√ß√£o 1 ‚Äì Usando a interface do Databricks

1. No Workspace, clique em **Repos**
2. Clique em **Add Repo**
3. Selecione **Clone remote Git repo**
4. Informe a URL do reposit√≥rio GitHub
5. Clique em **Create Repo**

### Op√ß√£o 2 ‚Äì Localmente via Databricks CLI

```bash
databricks repos create https://github.com/seu-usuario/seu-repositorio
```


##  Como rodar o projeto com Databricks Asset Bundles

### Adicione API keys

Adicione as chaves da Open AI e Tavily Search no arquivo .env.example e renomeio para .env.

## Jobs a serem executados

- project_setup_job - Job que faz a extra√ß√£o, processamento dos dados, registra o modelo de IA generativa e chama o modelo para gerar o realt√≥rio de SRAG (roda manualmente sob demanda).
- acute_resp_agent_job - Job que tenta extrair dados novos, aplica a transfomra√ß√†o nos dados, e chama o modelo para gerar o relat√≥rio de SRAG. Job executado diarimente de forma autom√°tica ap√≥s o deploy.

### Op√ß√£o 1 ‚Äì Usando a interface do Databricks

Para implantar e gerenciar este asset bundle, siga os passos abaixo:

1. Implanta√ß√£o

- Clique no **√≠cone de foguete de implanta√ß√£o** üöÄ na barra lateral esquerda para abrir o painel **Deployments** e, em seguida, clique em **Deploy**.

2. Execu√ß√£o de Jobs e Pipelines

- Execute o job implantado project_setup_job, clicando no bot√£o **Run** (play) no canto direito do job.
- O job acute_resp_agent_job ser√° executado diariamente para tentar extrair dados atualizados e gerar o relat√≥rio di√°rio de SRAG.


### Op√ß√£o 2 ‚Äì Localmente via Databricks CLI

1. Instalar o Databricks CLI

```bash
pip install databricks-cli
```

2. Autenticar no Databricks

```bash
databricks auth login
```
Siga as instru√ß√µes para autenticar via navegador.

A partir da raiz do reposit√≥rio:

4. Validar o bundle

```bash
databricks bundle validate
```

5. Fazer o deploy do bundle

```bash
databricks bundle deploy
```

6. Executar o pipeline

```bash
databricks bundle run
```

> O comando `run` executa os jobs definidos no arquivo `databricks.yml`, incluindo a execu√ß√£o do agente de IA e a gera√ß√£o dos relat√≥rios.

## Resultados

Ao final da execu√ß√£o, o projeto gera:
- Relat√≥rios **HTML** com m√©tricas de SRAG
- Gr√°ficos e indicadores epidemiol√≥gicos
- Texto explicativo gerado por IA, contextualizado com not√≠cias recentes

Os relat√≥rios podem ser acessados diretamente no **Databricks Workspace** ou exportados para compartilhamento.